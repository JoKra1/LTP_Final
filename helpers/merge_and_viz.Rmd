---
title: "Merge & Visualize"
date: "5/31/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(wordcloud)
library(tm)
library(RColorBrewer)
```

# Merge

```{r}
ind_files <- list.files("../data")
merged_files <- NULL
for (file in ind_files) {
  file <- ind_files[1]
  # Some checks
  valid <- grep("^IRAhandle_tweets_[1-9]+.csv$",file)
  if (length(valid) == 1) {
    ind_dat <- read.csv(paste0("../data/",file[valid]),sep=",")
    merged_files <- rbind(merged_files,ind_dat)
  }
  
}

write.csv(merged_files,"../data/merged.csv",sep=",",row.names = F)
```

# Column formatting

```{r}
# Change label and language columns to factors
merged_files$account_category <- as.factor(merged_files$account_category)
merged_files$account_type <- as.factor(merged_files$account_type)
merged_files$language <- as.factor(merged_files$language)
```

# Data summary

```{r}
# What labels are there
levels(merged_files$account_category)
levels(merged_files$account_type)

# What languages are there
levels(merged_files$language)
```

```{r}
set.seed(0)
reduced_data <- merged_files[,c("language",
                                "content",
                                "account_type",
                                "account_category")]
# Total summary
summary(reduced_data)

# Per category summaries + word-clouds
# Source for word-cloud code:
# https://towardsdatascience.com/create-a-word-cloud-with-r-bde3e7422e8a

for (cat in levels(reduced_data$account_category)) {
  sub_dat <- reduced_data[reduced_data$account_category == cat,]
  sub_dat <- sub_dat[sample(nrow(sub_dat)),] # Randomize
  
  # word-cloud struggles with some emojis and graphical characters
  # so make sure everything is converted to UTF-8 or ascii.
  # See:
  # https://stackoverflow.com/questions/9637278/r-tm-package-invalid-input-in-utf8towcs
  
  sub_dat$content <- iconv(sub_dat$content, 'UTF-8', 'ASCII')
  
  print(paste0("----- ", cat, " -----"))
  print(summary(sub_dat))
  print(length(sub_dat$language[sub_dat$language == "Russian"]))
  print(length(sub_dat$language[sub_dat$language == "German"]))
  
  # word cloud
  corpus <- Corpus(VectorSource(sub_dat[1:5000,"content"]))
  
  dtm <- TermDocumentMatrix(corpus) 
  matrix <- as.matrix(dtm) 
  words <- sort(rowSums(matrix),decreasing=TRUE) 
  df <- data.frame(word = names(words),freq=words)
  
  
  wordcloud(words = df$word, freq = df$freq, min.freq = 10,
            max.words=100, random.order=FALSE, rot.per=0.35,
            colors=brewer.pal(8, "Dark2"),scale = c(1.5,0.5))
  
  rm(corpus,dtm,matrix,words,df)

}
```

# Subset for training, validation, test

```{r}
# Drop everything un-necessary
set.seed(0) # twice is better, I am sure.

sub_dat <- merged_files[merged_files$language %in% c("English",
                                                     "Russian",
                                                     "German"),]

sub_dat <- sub_dat[,c("account_category","content","language")]

sub_dat <- sub_dat[sub_dat$account_category %in% c("RightTroll",
                                                   "NewsFeed",
                                                   "NonEnglish",
                                                   "LeftTroll"),]

# Drop NonEnglish column for general train, dev, test split since
# it is only needed for embeddings

sub_dat_class <- sub_dat[sub_dat$account_category != "NonEnglish",]

# Language specific split to ensure 60/20/20 for each language

sub_dat_eng <- sub_dat_class[sub_dat_class$language == "English",]
sub_dat_rus <- sub_dat_class[sub_dat_class$language == "Russian",]
sub_dat_ger <- sub_dat_class[sub_dat_class$language == "German",]

# Randomize
sub_dat_eng <- sub_dat_eng[sample(nrow(sub_dat_eng)),]
sub_dat_rus <- sub_dat_rus[sample(nrow(sub_dat_rus)),]
sub_dat_ger <- sub_dat_ger[sample(nrow(sub_dat_ger)),]

# Split
train_eng <- sub_dat_eng[1:floor(0.6 * nrow(sub_dat_eng)),]
val_eng <- sub_dat_eng[(floor(0.6 * nrow(sub_dat_eng)) + 1): floor(0.8 * nrow(sub_dat_eng)),]
test_eng <- sub_dat_eng[(floor(0.8 * nrow(sub_dat_eng)) + 1): nrow(sub_dat_eng),]

train_rus <- sub_dat_rus[1:floor(0.6 * nrow(sub_dat_rus)),]
val_rus <- sub_dat_rus[(floor(0.6 * nrow(sub_dat_rus)) + 1): floor(0.8 * nrow(sub_dat_rus)),]
test_rus <- sub_dat_rus[(floor(0.8 * nrow(sub_dat_rus)) + 1): nrow(sub_dat_rus),]

train_ger <- sub_dat_ger[1:floor(0.6 * nrow(sub_dat_ger)),]
val_ger <- sub_dat_ger[(floor(0.6 * nrow(sub_dat_ger)) + 1): floor(0.8 * nrow(sub_dat_ger)),]
test_ger <- sub_dat_ger[(floor(0.8 * nrow(sub_dat_ger)) + 1): nrow(sub_dat_ger),]

# Merge back
train <- rbind(train_eng,train_rus,train_ger)
val <- rbind(val_eng,val_rus,val_ger)
test <- rbind(test_eng,test_rus,test_ger)

# Write
write.csv(train,"../data/train_merged.csv",sep=",",row.names = F)
write.csv(val,"../data/val_merged.csv",sep=",",row.names = F)
write.csv(test,"../data/test_merged.csv",sep=",",row.names = F)
```

# Create sub-sets for embedding training:
```{r}
set.seed(0)
# We need more data with russian and german tweets, so extract those
# from the non-english category.
sub_dat_non_eng <- sub_dat[sub_dat$account_category == "NonEnglish",]

# Subsets
sub_dat_non_eng_rus <- sub_dat_non_eng[sub_dat_non_eng$language == "Russian",]
sub_dat_non_eng_ger <- sub_dat_non_eng[sub_dat_non_eng$language == "German",]

# Shuffle
sub_dat_non_eng_rus <- sub_dat_non_eng_rus[sample(nrow(sub_dat_non_eng_rus)),]
sub_dat_non_eng_ger <- sub_dat_non_eng_ger[sample(nrow(sub_dat_non_eng_ger)),]

# Only train/test split to maximize data
train_rus_emb <- sub_dat_non_eng_rus[1:floor(0.75 * nrow(sub_dat_non_eng_rus)),]
test_rus_emb <- sub_dat_non_eng_rus[(floor(0.75 * nrow(sub_dat_non_eng_rus)) + 1): nrow(sub_dat_non_eng_rus),]

train_ger_emb <- sub_dat_non_eng_ger[1:floor(0.75 * nrow(sub_dat_non_eng_ger)),]
test_ger_emb <- sub_dat_non_eng_ger[(floor(0.75 * nrow(sub_dat_non_eng_ger)) + 1): nrow(sub_dat_non_eng_ger),]

# Drop some English tweets to achieve better balance
train_eng_emb <- train_eng[1:480000,]
test_eng_emb <- test_eng[1:150000,]

train_emb <- rbind(train_eng_emb,train_rus_emb,train_ger_emb)
test_emb <- rbind(test_eng_emb,test_rus_emb,test_ger_emb)

write.csv(train_emb,"../data/train_emb_merged.csv",sep=",",row.names = F)
write.csv(test_emb,"../data/test_emb_merged.csv",sep=",",row.names = F)
```

